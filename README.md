
# EDA Titanic (Kaggle) ‚Äî Gu√≠a de uso (Windows 10 + Git Bash + uv)

Este repositorio contiene un ejemplo de **An√°lisis Exploratorio de Datos (EDA)** del cl√°sico dataset **Titanic** (Kaggle), pensado para principiantes. La gu√≠a explica c√≥mo instalar dependencias con **uv**, descargar los datos de **Kaggle**, abrir el proyecto en **JupyterLab** y ejecutar el notebook paso a paso.

Se busca tambi√©n la pr√°ctica de cargado y limpieza de datos, estad√≠sticas descriptivas y visualizaci√≥n con Python, pandas, matplotlib y seaborn, adem√°s de el flujo de trabajo con uv y JupyterLab. No est√° orientado a producci√≥n; los resultados son demostrativos y con fines estrictamente educativos.

---

# Introducci√≥n al EDA

Un **An√°lisis Exploratorio de Datos (EDA)** es esencial en cualquier proyecto de datos. 
Es b√°sicamente ese primer vistazo que le damos a un dataset o un conjunto de datos, para conocerlo y entenderlo antes de aplicar modelos o t√©cnicas avanzadas de an√°lisis o de entrenar cualquier modelo de IA, revis√°ndolo por si hay errores en el mismo, con valores at√≠picos, falta de datos y/o patrones interesantes.

‚ÄúSi no hacemos EDA antes de analizar nuestros datos es como armar un rompecabezas sin haber mirado la imagen.‚Äù ‚ÄúEs como un detective que investiga nuestros datos.‚Äù

El **An√°lisis Exploratorio de Datos (EDA)**, fue **desarrollado por el matem√°tico estadounidense John Tukey en la d√©cada de 1970** y se caracteriza por ser un proceso investigativo en el que se utilizan herramientas estad√≠sticas descriptivas y de visualizaci√≥n para examinar conjuntos de datos (el dataset), descubrir patrones, detectar anomal√≠as, probar hip√≥tesis y verificar supuestos mediante estad√≠sticas de resumen y representaciones gr√°ficas.

El EDA combina m√©todos estad√≠sticos y visualizaciones gr√°ficas para:

    ‚Ä¢	Comprender la estructura y caracter√≠sticas de los datos
    ‚Ä¢	Identificar patrones, tendencias y relaciones entre variables
    ‚Ä¢	Detectar valores at√≠picos y anomal√≠as
    ‚Ä¢	Evaluar la calidad de los datos (valores faltantes, inconsistencias)
    ‚Ä¢	Generar hip√≥tesis para an√°lisis posteriores
    ‚Ä¢	Preparar los datos para modelado de Machine Learning

    
El EDA no buscar confirmar hip√≥tesis estad√≠sticas preestablecidas, sino generar nuevas preguntas. Se trata de analizar los datos con curiosidad y sin prejuicios, permitiendo obtener patrones inesperados y/o relaciones ocultas que puedan guiar a futuros an√°lisis. El objetivo es conocer los datos antes de realizar cualquier tipo de hip√≥tesis para guiar a los analistas en la toma de decisiones, es obtener un dataset "limpio", preparado para su an√°lisis y modelado. Es conocer los datos y qu√© se puede aprender de ellos. Para ello se aplican estrategias para su limpieza y transformaci√≥n, que redundar√°n en la calidad de los modelos predictivos y anal√≠ticos.  

En esta gu√≠a, exploramos algunas t√©cnicas y herramientas para realizar un an√°lisis exploratorio efectivo.

---

## 1) Requisitos

- **Git Bash** (puedes usar VS Code si quieres).
- **uv** instalado y accesible en tu PATH. Comprueba:
  ```bash
  uv --version
  ```
- **Python 3.9+** (recomendado 3.10‚Äì3.12).
- **JupyterLab** (se instala como dependencia).
- **Cuenta Kaggle** y **kaggle.json** (para descargar los CSV).

> Si no quieres usar Kaggle, puedes cargar el dataset de `seaborn` (necesita internet). En este repo lo usamos desde **Kaggle** para que cualquiera pueda replicar sin depender de la conectividad.

---

## 2) Instalaci√≥n de dependencias

### Opci√≥n A ‚Äî Proyecto con `pyproject.toml` (recomendada con uv)
Si este repositorio ya trae un `pyproject.toml`, simplemente:

```bash
# 1) Clona el repo
git clone https://github.com/TU_USUARIO/eda-titanic-kaggle.git
cd eda-titanic-kaggle

# 2) Crea el entorno
uv venv .venv

# 3) Instala dependencias declaradas en el TOML
uv sync
```

> Si **no** existe `pyproject.toml` y quieres crearlo con uv:
> ```bash
> uv init --name eda-titanic-kaggle
> uv add pandas matplotlib seaborn scipy scikit-learn jupyterlab ipykernel kaggle
> uv sync
> ```

### Opci√≥n B ‚Äî `requirements.txt` (alternativa cl√°sica)
Si prefieres gestionar deps con `requirements.txt`:

```bash
uv venv .venv
source .venv/Scripts/activate
uv pip install -r requirements.txt
```

> **No mezcles** A y B en el mismo proyecto. Elige un m√©todo y qu√©date con √©l.

---

## 3) Datos de Kaggle (descarga y preparaci√≥n)

1) En la web de Kaggle ‚Üí **Account** ‚Üí **Create New API Token** ‚Üí se descarga `kaggle.json`.
2) Col√≥calo en tu HOME de usuario:
   ```bash
   mkdir -p /c/Users/USUARIO/.kaggle
   mv /c/Users/USUARIO/Downloads/kaggle.json /c/Users/USUARIO/.kaggle/kaggle.json
   chmod 600 /c/Users/USUARIO/.kaggle/kaggle.json
   ```
3) Descarga el dataset de la competici√≥n Titanic y descomprime en `data/`:
   ```bash
   uvx kaggle competitions download -c titanic -p data
   unzip data/titanic.zip -d data
   # Esperado: data/train.csv, data/test.csv, data/gender_submission.csv
   ```

---

## 4) Ejecutar el proyecto en JupyterLab

```bash
# Lanza JupyterLab
# (Con venv activado:)
source .venv/Scripts/activate
jupyter lab
# (O sin activar el venv:)
# uv run jupyter lab
```

En JupyterLab:
1. Abre el notebook: `notebooks/eda-titanic-kaggle.ipynb`.
2. Selecciona el **kernel** del entorno (men√∫ **Kernel ‚Üí Change Kernel‚Ä¶**).  
   - Si no aparece, cr√©alo una vez:
     ```bash
     python -m ipykernel install --user --name eda-titanic --display-name "Python (eda-titanic)"
     ```
     Cierra y vuelve a abrir JupyterLab.
3. Ejecuta todo: **Run ‚Üí Run All Cells** (o usa `Shift+Enter` por celda).

Los gr√°ficos aparecen **inline** (debajo de cada celda). Los CSV limpios se guardan en la carpeta del proyecto (p. ej. `titanic_clean.csv`, `titanic_encoded.csv`).

---

## 5) Estructura recomendada del proyecto

```
eda-titanic-kaggle/
‚îú‚îÄ .venv/                      # entorno virtual (no subir a git)
‚îú‚îÄ data/                       # CSVs descargados de Kaggle (opcional subir)
‚îÇ  ‚îú‚îÄ train.csv
‚îÇ  ‚îú‚îÄ test.csv
‚îÇ  ‚îî‚îÄ titanic.zip
‚îú‚îÄ figures/                    # (opcional) PNGs si decides guardarlos
‚îú‚îÄ notebooks/
‚îÇ  ‚îî‚îÄ eda-titanic-kaggle.ipynb
‚îú‚îÄ pyproject.toml              # O, alternativamente, requirements.txt
‚îú‚îÄ requirements.txt            # (si usas este m√©todo)
‚îú‚îÄ README.md
‚îî‚îÄ .gitignore
```

**.gitignore** sugerido:
```
.venv/
__pycache__/
*.ipynb_checkpoints
data/*.zip
.kaggle/
```

> Si no quieres subir los CSV de Kaggle, a√±ade `data/` completo al `.gitignore` y no los incluyas en `git add`.

---

## 6) ¬øNecesito guardar im√°genes en `figures/`?

**No es obligatorio.** Las salidas de las celdas (gr√°ficas incluidas) quedan **embebidas** dentro del `.ipynb`, por lo que **GitHub** las muestra al visualizar el notebook.  
Solo guarda PNGs en `figures/` si:
- Quieres reutilizarlos (README, informes externos).
- Te preocupa el tama√±o del `.ipynb` o su render en GitHub en notebooks muy pesados.
- Prefieres versionar im√°genes sueltas.

Para guardar adem√°s de mostrar inline:
```python
# antes de plt.show():
import os; os.makedirs("figures", exist_ok=True)
plt.savefig("figures/plot_hist_age.png", dpi=150, bbox_inches="tight")
plt.show()
```

Puedes insertar un PNG guardado en una **celda Markdown** y hacer la referencia al PNG generado en el propio README.md con:
```markdown
![Hist edad](../figures/plot_hist_age.png)
```

---

## 7) Descripciones para cada gr√°fica (a√±adir como celda Markdown debajo)

- **Histograma de edad** (`age`): distribuci√≥n de edades; permite ver asimetr√≠as, modas y huecos. √ötil para decidir imputaci√≥n/transformaciones.
- **Conteo `survived` (0/1)**: balance de clases; si hay desbalance fuerte, puede afectar evaluaci√≥n/modelado.
- **Boxplot `fare` por `survived`**: compara tarifas entre sobrevivientes y no; suele observarse mayor `fare` en quienes sobrevivieron (relaci√≥n con `pclass`).
- **Conteo `sex` con `hue=survived`**: supervivencia por sexo; en Titanic se observa mayor tasa en mujeres (y ni√±os).
- **Matriz de correlaci√≥n (num√©ricas)**: relaci√≥n lineal entre variables num√©ricas; √∫til para detectar colinealidades y posibles predictoras.
- **Boxplot `age`** (outliers IQR): valores extremos en `age`; orientar winsorizaci√≥n, recorte o transformaciones.
- **Boxplot `fare`** (outliers IQR): `fare` suele tener cola larga y outliers altos; considerar escalado/winsorizaci√≥n.

> A√±ade una **celda de texto (Markdown)** debajo o encima de **cada** celda con gr√°fico y pega la descripci√≥n correspondiente (puedes adaptarla a lo que observes en tus datos).

---

## 8) Subir a GitHub

```bash
git init
git add notebooks/eda-titanic-kaggle.ipynb README.md .gitignore
# Si usas pyproject.toml:
git add pyproject.toml
# O si usas requirements.txt:
git add requirements.txt
# (Opcional) Figuras y/o datos si decides subirlos:
# git add figures/
# git add data/train.csv data/test.csv

git commit -m "EDA Titanic: notebook, dependencias y gu√≠a de uso"
git branch -M main
git remote add origin https://github.com/TU_USUARIO/eda-titanic-kaggle.git
git push -u origin main
```

---

## 9) Soluci√≥n de problemas comunes

- **`kaggle: Could not find kaggle.json`** ‚Üí coloca el token en `C:\Users\USUARIO\.kaggle\kaggle.json` y repite la descarga.
- **El kernel no aparece** ‚Üí instala con `python -m ipykernel install ...` y reinicia JupyterLab.
- **Error al imputar (`ValueError: 2`)** ‚Üí usa `.ravel()` al asignar `fit_transform`, e.g. `df["age"] = SimpleImputer(...).fit_transform(df[["age"]]).ravel()`.
- **`describe(include="object")` falla** ‚Üí usa `include=["object","category"]` o detecta columnas antes.

---

¬°Listo! Con esto, cualquier usuario podr√° instalar, ejecutar el notebook, ver los resultados y (si quiere) guardar las gr√°ficas como archivos separados.

---

# Notebook - EDA del Titanic con datos de Kaggle

# Configuraci√≥n inicial: Imports y ajustes
## Celda 1 ‚Äî Imports y ajustes:
### Utilidades (guardar im√°genes/tablas; no toca README)

---

# FASE 1 Exploraci√≥n incial. Reconocimiento del Dataset: 
## Celda 2 ‚Äî cargar Kaggle CSV (normalizamos nombres)
### Carga 891 pasajeros, 15 caracter√≠sticas Identifica tipos: num√©ricos vs categ√≥ricos vs texto

**Tablas:**
![Head](figures/tbl_head_raw.png)

![Tipos](figures/tbl_dtypes.png)

![Shape](figures/tbl_shape.png)

**Qu√© se hace:**
- Se carg√≥ `data/train.csv` de Kaggle.
- Normalizaci√≥n de nombres: `Survived‚Üísurvived`, `Pclass‚Üípclass`, etc.
- Ajuste de tipos: `survived`‚Üíint, `sex`/`embarked`‚Üícategory.

---

# FASE 2 Evaluaci√≥n de la calidad: 
## Celda 3 ‚Äî Inspecci√≥n y diagn√≥stico:
### Detecta: age (177 nulos), cabin (687 nulos), embarked (2 nulos) Estad√≠sticas: 38% supervivencia, edades 0.42-80 a√±os, tarifas 0-512¬£

**Qu√© es:** Vista general (nulos, estad√≠stica num√©rica y categ√≥rica, cardinalidad).  
**Qu√© muestra:** Columnas con m√°s nulos; orden de magnitudes y dispersi√≥n; niveles de categ√≥ricas.  
**Insight:** Priorizar imputaci√≥n/limpieza en variables con muchos nulos.

![Nulos](figures/tbl_nulls.png)

![Num√©ricas](figures/tbl_desc_num.png)

![Categ√≥ricas](figures/tbl_desc_cat.png)

![Cardinalidad](figures/tbl_cardinality.png)

---

# FASE 3 Limpieza (Celda 4 a Celda 6)
## Celda 4 ‚Äî limpieza (duplicados, imputaci√≥n, feature)
### Imputa age con mediana (m√°s robusta que media) Imputa embarked con moda Crea family_size = siblings + parents + 1

**Qu√© es:** Resultados tras limpiar duplicados, imputar y crear `family_size`.  
**Qu√© muestra:** Estado del dataset despu√©s de imputaci√≥n; nulos restantes (si los hay).  
**Insight:** Dataset listo para an√°lisis bivariado/multivariado y modelado b√°sico.

![Head post-clean](figures/tbl_head_post_clean.png)

![Nulos post](figures/tbl_nulls_post.png)


## Celda 5: An√°lisis Univariado (hist edad + conteos survived) 

**Qu√© es:** Histograma de `age` y barras de `survived` (con tabla de conteo).  
**Qu√© muestra:** Forma de la distribuci√≥n de edades; balance de clases (0/1).  
**Insight:** Si hay fuerte desbalance en `survived`, afectar√° el modelado.

![Hist edad](figures/plot_hist_age.png)


#### plot_hist_age.png
```bash
**Qu√© es:** Histograma de distribuci√≥n de edades
**Qu√© muestra:** Pico en 20-30 a√±os, pocos ni√±os y ancianos
**Insight:** Mayor√≠a pasajeros eran j√≥venes adultos
```

![Conteo survived](figures/plot_count_survived.png)

![Tabla survived](figures/tbl_survived_counts.png)

#### plot_count_survived.png
```bash
**Qu√© es:** Gr√°fico de barras de supervivencia
**Qu√© muestra:** 549 muertos vs 342 vivos (38% supervivencia)
**Insight:** Mayor√≠a de pasajeros muri√≥ en el desastre
```

### Celda 6: An√°lisis Bivariado

**Qu√© es:** Comparaciones de `fare` y `sex` contra `survived`.  
**Qu√© muestra:** Supervivientes tienden a pagar **tarifas m√°s altas**; mujeres sobreviven m√°s que hombres.  
**Insight:** La **clase social** y el **sexo** influyen fuertemente en la supervivencia.

![Boxplot fare~survived](figures/plot_box_fare_survived.png)

#### plot_box_fare_survived.png
```bash
**Qu√© es:** Boxplot de tarifas por supervivencia
**Qu√© muestra:** Supervivientes pagaron tarifas M√ÅS ALTAS
**Insight:** La clase social influy√≥ en supervivencia
```

![Sexo vs survived](figures/plot_count_sex_survived.png)

#### plot_count_sex_survived.png
```bash
**Qu√© es:** Barras agrupadas de sexo vs supervivencia
**Qu√© muestra:** Mayor√≠a mujeres vivas, mayor√≠a hombres muertos
**Insight:** "Mujeres y ni√±os primero" se cumpli√≥
```
---

# FASE 4 An√°lisis profundo. Outliers:
### Celda 7: Matriz de Correlaci√≥n y outliers
### Detecta usando m√©todo IQR Conserva outliers como leg√≠timos (ancianos, primera clase)

![Correlaci√≥n](figures/plot_corr_heatmap.png)

#### plot_corr_heatmap.png
```bash
**Qu√© es:** Matriz de correlaci√≥n entre variables num√©ricas
**Qu√© muestra:** Relaciones entre edad, tarifa, clase, familia, etc.
**Insight:** Identificar variables redundantes
```

![Box age](figures/plot_box_age.png)

![Box fare](figures/plot_box_fare.png)

#### plot_box_age.png y plot_box_fare.png
```bash
**Qu√© son:** Boxplots para detecci√≥n de outliers
**Qu√© muestran:** Ancianos y tarifas altas como valores at√≠picos
**Insight:** Outliers leg√≠timos (no errores)
```

# Celda 8: Validaci√≥n estad√≠stica. Tests de hip√≥tesis:
### T-test: Confirma que supervivientes pagaron m√°s (p < 0.05) Chi-cuadrado: Confirma asociaci√≥n sexo-supervivencia (p < 0.05)

**Qu√© es:** Heatmap de correlaciones num√©ricas y boxplots con IQR para outliers.  
**Qu√© muestra:** Relaciones lineales entre num√©ricas; `fare` suele tener cola larga con outliers altos.  
**Insight:** Considerar **escalado/winsorizaci√≥n** en `fare` y revisar colinealidades antes del modelado.

![Correlaci√≥n](figures/plot_corr_heatmap.png)

![Box age](figures/plot_box_age.png)

![Box fare](figures/plot_box_fare.png)

---

# FASE 5 Conclusiones y preparaci√≥n: (Celda 9: exportar CSVs limpios)

El an√°lisis exploratorio de datos (EDA) proporciona una comprensi√≥n profunda de las caracter√≠sticas de los datos y sus relaciones. Al final de este proceso, es fundamental sintetizar los hallazgos, identificar problemas y formular recomendaciones para los siguientes pasos en el an√°lisis o en la construcci√≥n de modelos.

```bash
Temas cubiertos:

- Hallazgos Principales

El objetivo del resumen es destacar los hallazgos m√°s importantes y relevantes que surgieron del EDA. Estos hallazgos pueden incluir:

 **‚Ä¢	Distribuciones de las variables:** C√≥mo se distribuyen los datos (normal, sesgada, etc.).
 **‚Ä¢	Relaciones entre variables:** Identificaci√≥n de correlaciones significativas o relaciones entre variables predictoras y la variable objetivo.**
 **‚Ä¢	Datos at√≠picos y valores faltantes:** Determinar si existen valores at√≠picos o si falta informaci√≥n importante en las variables.**
 **‚Ä¢	Caracter√≠sticas importantes:** Variables que tienen un impacto significativo en la variable objetivo, basadas en an√°lisis estad√≠sticos o t√©cnicas de machine learning.**

Un buen resumen debe proporcionar una visi√≥n clara de las caracter√≠sticas del conjunto de datos y c√≥mo estas caracter√≠sticas podr√≠an influir en el modelo.

- Problemas Identificados

Durante el EDA, es com√∫n encontrar problemas que podr√≠an afectar la calidad del an√°lisis o la precisi√≥n de los modelos. Algunos de los problemas m√°s comunes incluyen:

 **‚Ä¢	Valores faltantes:** Grandes cantidades de datos ausentes en algunas columnas que podr√≠an afectar el rendimiento del modelo.**
 **‚Ä¢	Outliers:** Valores at√≠picos que pueden distorsionar las distribuciones y afectar la exactitud de los modelos predictivos.**
 **‚Ä¢	Multicolinealidad:** Variables altamente correlacionadas entre s√≠, lo que puede causar problemas en modelos de regresi√≥n lineales o algoritmos sensibles a la multicolinealidad.**
 **‚Ä¢	Distribuciones sesgadas:** Variables que no siguen una distribuci√≥n normal y que pueden requerir transformaciones para mejorar el an√°lisis.**

Identificar estos problemas es crucial para decidir c√≥mo tratarlos antes de avanzar al modelado.

- Recomendaciones para Pasos Siguientes

Basado en los hallazgos y problemas identificados, se deben proponer recomendaciones claras para el an√°lisis posterior. Algunas recomendaciones comunes incluyen:

 **‚Ä¢	Manejo de valores faltantes:** Imputar valores faltantes o eliminar registros, dependiendo de la cantidad y la importancia de los datos faltantes.
 **‚Ä¢	Tratamiento de outliers:** Eliminar, transformar o manejar los outliers, dependiendo de su impacto en el an√°lisis.
 **‚Ä¢	Selecci√≥n de caracter√≠sticas:** Elegir las caracter√≠sticas m√°s relevantes basadas en su importancia para la variable objetivo, utilizando t√©cnicas como la selecci√≥n autom√°tica de caracter√≠sticas o la eliminaci√≥n manual de aquellas con baja correlaci√≥n.
 **‚Ä¢	Transformaciones de datos:** Normalizar o estandarizar variables cuando sea necesario para mejorar el rendimiento de ciertos modelos.
 **‚Ä¢	Pruebas de validaci√≥n:** Realizar validaciones cruzadas o pruebas adicionales para verificar la calidad del modelo antes de la implementaci√≥n.
```


## üéØ INSIGHTS PRINCIPALES DESCUBIERTOS tras el an√°lisis de los datos:
```bash
- Factor g√©nero es CR√çTICO 
- Diferencia dram√°tica hombre vs mujer Clase social importa 
- Tarifas altas = mayor supervivencia Protocolo mar√≠timo cumplido 
- "Mujeres y ni√±os primero" Variables engineered √∫tiles 
- family_size puede mejorar predicciones Datos de calidad 
- Pocos problemas tras limpieza
```

## üìã ARCHIVOS CSV obtenidos (Celda 9) (2 datasets procesados):

#### 1. titanic_clean.csv
```bash
Qu√© es: Datos originales pero limpios
Contiene: Valores imputados, sin duplicados, tipos corregidos
Uso: Para an√°lisis posterior manteniendo interpretabilidad
```

#### 2. titanic_encoded.csv
```bash
Qu√© es: Datos codificados para Machine Learning
Contiene: Variables categ√≥ricas convertidas a n√∫meros (one-hot encoding)
Uso: Listo para entrenar algoritmos de IA
```


Este script es un ejemplo perfecto de EDA profesional aplicando toda la teor√≠a que estudiamos.

